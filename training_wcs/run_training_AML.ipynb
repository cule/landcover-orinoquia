{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  # default is ‘last_expr’\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import (Workspace, Experiment, Datastore, Dataset, \n",
    "                          ContainerRegistry, ScriptRunConfig, RunConfiguration, \n",
    "                          Run)\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "from azureml.tensorboard import Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Version of AML: {}'.format(azureml.core.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training on AML\n",
    "We used this notebook to run experiments on [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning-services/) earlier in the project, and since switched to running experiments on [Data Science Virtual Machines](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/). This notebook is no longer maintained but is kept here as an example of using the AML Python SDK. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide credentials\n",
    "\n",
    "Provide the account name and the key to the storage account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account_name = os.environ.get('STORAGE_ACCOUNT_NAME')\n",
    "storage_account_key = os.environ.get('STORAGE_ACCOUNT_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the AML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.get(name='<workspace_name>', \n",
    "                   subscription_id='<subscription_id>', \n",
    "                   resource_group='<resource_group_name>')\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target = ws.compute_targets['gpu-nc6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = 'wcsorinoquia'\n",
    "container_name = 'wcs-orinoquia'\n",
    "\n",
    "datastore = None\n",
    "for name, ds in ws.datastores.items():\n",
    "    if name == datastore_name:\n",
    "        datastore = ds\n",
    "        \n",
    "if datastore is None:\n",
    "    datastore = Datastore.register_azure_blob_container(\n",
    "         workspace=ws, \n",
    "         datastore_name=datastore_name, \n",
    "         container_name=container_name,\n",
    "         account_name=storage_account_name, \n",
    "         account_key=storage_account_key,\n",
    "         create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = DataReference(datastore=datastore,\n",
    "                         data_reference_name=datastore_name,\n",
    "                         mode='mount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(data_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an AML experiment and run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'wcs_baseline_20200506'\n",
    "\n",
    "exp_folder = './scripts_and_config'\n",
    "\n",
    "tags = {\n",
    "    'model': 'unet, feature scale 2',\n",
    "    \n",
    "    'starting_from': 'None',\n",
    "    \n",
    "    'init_learning_rate': str(1e-4),\n",
    "    \n",
    "    'loss_weights': 'all the same, set to 1',\n",
    "    \n",
    "    'batch_size': '32',\n",
    "    \n",
    "    'imagery': 'full_sr_median_2013_2014',\n",
    "    \n",
    "    'bands': '2, 3, 6, 7, NDVI'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy('../viz_utils.py', exp_folder)\n",
    "\n",
    "# copytree requires that the destination folder must not already exist\n",
    "os.makedirs(os.path.join(exp_folder, 'constants'), exist_ok=True)\n",
    "os.makedirs(os.path.join(exp_folder, 'constants', 'class_lists'), exist_ok=True)\n",
    "os.makedirs(os.path.join(exp_folder, 'constants', 'splits'), exist_ok=True)\n",
    "\n",
    "copy('../constants/landsat_bands_info.py', os.path.join(exp_folder, 'constants'))\n",
    "copy('../constants/class_lists/lulc_wcs_label_maps.json', os.path.join(exp_folder, 'constants', 'class_lists'))\n",
    "copy('../constants/splits/full_sr_median_2013_2014_splits.json', os.path.join(exp_folder, 'constants', 'splits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyTorch.get_supported_versions()\n",
    "PyTorch.DEFAULT_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--config_module_path': 'experiments.baseline.baseline_config'\n",
    "}\n",
    "\n",
    "pt_est = PyTorch(\n",
    "    source_directory=exp_folder,\n",
    "    script_params=script_params,\n",
    "    entry_script='train.py',  # relative to source_directory\n",
    "    \n",
    "    inputs=[data_ref],\n",
    "    \n",
    "    compute_target=compute_target,\n",
    "    node_count=1,\n",
    "    use_gpu=True,\n",
    "    \n",
    "    # framework_version='1.3.1',  # this version gets used, but can't specify it\n",
    "    \n",
    "    pip_packages=['pillow==6.1', 'tensorflow==1.14.0', \n",
    "                 'numpy', 'pandas', 'matplotlib', \n",
    "                  'geopandas', 'rasterio', 'scikit-image',\n",
    "                 ]\n",
    "\n",
    "# Both of the following did not work (using conda does not work) \n",
    "# - couldn't import rasterio.windows.Window if using conda_packages instead of pip_packages\n",
    "\n",
    "# conda_dependencies_file_path='training_environment.yml'\n",
    "\n",
    "#     conda_packages=['numpy', 'pandas', 'matplotlib', \n",
    "#                     'geopandas', 'rasterio', 'scikit-image',\n",
    "#                     'tensorflow==1.14.0', 'pillow==6.1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(pt_est, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_details()['runId']\n",
    "run.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To archive an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='name_of_exp_to_archive')\n",
    "exp.archive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start TensorBoard\n",
    "\n",
    "https://docs.microsoft.com/bs-latn-ba/azure/machine-learning/service/how-to-monitor-tensorboard\n",
    "\n",
    "We wrote logs to ./logs, which AML uploads to Artifact Service and makes available to a TensorBoard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover the Run object if needed\n",
    "run_id = 'wcs_baseline_<run_id>'  # get the run_id from above cell or from Azure Portal\n",
    "run = Run(exp, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Tensorboard constructor takes an array of runs\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when done, call the stop() method of the Tensorboard object, or it will stay running even after your job completes.\n",
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorBoard stops loading after a little while and needs to be restarted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wcs] *",
   "language": "python",
   "name": "conda-env-wcs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
